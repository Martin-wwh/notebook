# Redis

## Redis基础数据结构及应用

基础五类型：

> list、set、zset、hash、string

## Redis原理

### 线程IO模型

<mark>Redis是单线程程序！</mark>他高并发的能力来源于多路复用，即linux的epoll。

1. 多路复用：
   
   操作系统提供给用户程序的API，他接受read_dfs和write_dfs操作符，同时携带一个timeout参数。在这个timeout时间内有IO事件到来，则交给程序做后续处理，处理完了回来继续监听。
   
   <mark>用一个线程监听多个通道描述符的读写操作，减少线程切换时内核切换到用户模式的开销。</mark>

2. 指令队列：
   
   redis会将每个客户端套接字发来的命令关联到一个指令队列中。然后按照这个队列的顺序来执行命令。

3. 响应队列：
   
   每个客户端也对应了一个响应队列，如果这个响应队列为空，则会将read_dfs指令从epoll中移除，防止出现没有数据，但是事件轮训API一直调用导致CPU使用率升高。

### 持久化

Redis主节点一般不会进行持久化。都是用从节点来持久化。

Redis的持久化有两种：

- 快照
  
  <mark>快照是一次全量备份</mark>，是内存的二进制序列化形式，在存储上非常紧凑。

- AOF
  
  <mark>AOF日志记录的是对数据进行操作的指令文本。</mark>数据库重启时需要加载AOF重放操作复原，为防止AOF文件过大导致复原时间过长，因此AOF需要重写来瘦身。
1. 快照原理
   
   Redis是单线程程序，内存快照是文件IO操作，是不能使用多路复用API的。他需要一边进行内存快照的同时，处理客户端响应。而且在这过程中，可能正在快照的hash被客户端删除了。
   
   **Redis是如何一边进行快照，一边响应请求的呢？**
   
   <mark>Redis使用操作系统的多进程COW(Copy On Write)机制来实现快照持久化的。</mark>
   
   **什么是COW呢？**
   
   首先，我们需要了解**fork**函数。Redis在持久化过程中通过glibc的函数fork来产生一个子进程，父进程继续响应客户端操作，**子进程用来进行内存快照**。子进程和父进程共享内存里面的代码和数据段。
   
   子进程是将数据持久化，不会修改数据，父进程会进行修改。
   
   COW的作用是父进程在修改数据时，会将该数据所在的数据页复制出来，父进程对该数据页进行操作，对于子进程来说，它只会处理原始的数据，父进程的修改对其是不可见的。

2. AOF原理
   
   AOF存储的是Redis服务器的顺序指令集合。AOF**只记录对于内存数据进行修改**的指令记录。
   
   指令到达Redis之后，进行参数校验，逻辑处理。成功之后写入AOF日志，**因此Redis是先执行再写日志的。**
   
   <mark>AOF重写</mark>
   
   Redis会fork一个子进程来遍历AOF内存，将对某个键的多个操作转化为一条记录序列化到一个新的AOF日志文件中。譬如客户端对某个list操作，分别插入ABCDE5个对象，执行了5条指令，重写之后只需要一次PUSH指令进行。这就是瘦身操作。
   
   **AOF缓存**
   
   子进程在AOF的过程中，主进程还在持续的执行客户端操作。因此在fork时，会启动Redis的AOF缓存，用来记录AOF重写过程中发生的新指令，在AOF文件重写完成后追加到文件中。
   
   **fsync**
   
   AOF是文件形式存在的，当程序对AOF进行写入时，实际上是记录在内核为文件描述符分配的一个缓存空间中，然后内核会异步的将缓存数据刷入磁盘。
   
   **但是如果在刷盘之前机器宕机怎么办**
   
   Linux提供了fsync来强制将文件的缓存数据刷回磁盘。Redis默认1s执行一次fsync，因此最多只会丢失1s的数据。

Redis4.0之后采用RDB+增量AOF来执行重启的恢复。

### 管道

管道是一项客户端技术，在管道中的指令，管道会改变指令列表的执行顺序，大幅节省IO时间。

客户端在普通情况下，需要执行写-读-写-读四个操作才完整地执行了两条指令，管道通过调整执行顺序，变成写-写-读-读，连续的读、写指令合并成一次访问，只需要花费一次网络请求。

管道中P参数指定了可以并行的请求数量，这个数据不是越大越好，它跟CPU的性能有关，如果CPU达到瓶颈，并发量就无法继续提升了。

**请求交互流程：**

- 客户端进程通过调用write函数吧指令消息写到内核为套接字分配的发送缓存区send buffer。

- 客户端内核将发送缓存区数据发送到网卡设备，网卡将数据发送给网络路由

- 服务器内核将网卡数据复制到套接字的接受缓存区recv buffer

- 服务器进程调用read将数据从缓存区取出消息处理

- 服务器处理完毕，调用write函数吧响应数据写到send buffer

- 服务器内核将send buffer的数据复制到网卡， 网卡将数据发出

- 客户端内核将网卡数据复制到recv buffer

- 客户端程序从recv buffer中取数据处理。
  
  调用write函数本身只要将数据发送到send buffer就会返回，是非阻塞的，但是如果缓存区满了，则需要等待缓存区空闲，这就是IO写操作真正耗时所在。
  
  read函数只要缓存区有数据就会返回，但是如果没有数据就需要等待数据到来，这是IO读操作耗时所在。
  
  `redis.get(key)`write将数据发送到缓存区就返回，但是read需要等到响应消息返回，这才是一次网络IO真正耗时的地方。
  
  对于管道来说，write操作根本没有耗时，第一个read需要等待一个网络的来回开销，然后所有的响应消息都已经送到内核的读缓存了。

### 事务

1. 事务指令
   
   redis 事务指令： multi、exec、discard。multi指示事务的开始，exec指示事务的执行、 discard指示事务的丢弃

2. 事务原子性
   
   <mark>Redis 的事务并不具备原子性，它只满足了事务隔离中的串行化，事务的执行不被其他</mark>事务打断

3. 优化
   
   事务在发送指令时时一个个发送给redis的，这中间存在大量的请求交互流程，我们可以用管道来将事务的指令一次性提交。

4. 并发数据安全
   
   Redis提供了一种乐观锁<mark>watch</mark>。
   
   watch在事务提交之前会叮嘱一个或多个关键变量。当客户端执行事务时，会检测watch的变量是否发生更改，如果更改过了，就会返回NULL回复告知客户端执行失败。
   
   <mark>watch只能在multi之前顶住关键变量。</mark>

### PubSub: 多播机制

阻塞消费：使用listen阻塞监听消息来处理，这点同blpop原理是一样的。

订阅模式：订阅可以订阅多个主题，我们也可以使用Pattern Subscribe。

```redis
//订阅多个主题
subscribe a b c
//使用正则订阅主题
psubscribe codehold.*
```

缺点：无法持久化， 某个消费者下线，数据对于该消费者是丢失的。

### 小对象压缩ziplist

如果Redis内部管理的集合数据结构很小，就会采用紧凑存储形式压缩存储。

不过每个存储集合都有个存储界限，超过这个界限就会使用表针存储结构。

### 内存回收机制

Redis并不总会将空闲的内存归还给操作系统。因为操作系统是以页为单位来回收内存的，这个页上只要还有数据，就不会被回收，但是这些空闲内存还是会被redis 复用的。

## 集群篇

1. 主从同步
   
   - CAP原理
     
     分布式中间件的理论基石：CAP原理
     
     - C：Consistent 一致性
     
     - A：Avaliable 可用性
     
     - P：Partition tolerance 分区容忍性
     
     分布式系统各个节点是分布在不同的机器上的，如果某台机器网络断开，这种网络断开的场景叫**网络分区**。
     
     网络分区发生时，我们对一个节点的修改无法同步到另一个节点，那边就不能达到一致性的要求，除非牺牲可用性，暂停分布式节点服务，不提供数据修改的服务直到网络状况恢复。
   
   - 最终一致性
     
     Redis主从同步是异步的，即使在主从网络断开的情况下，主节点依旧可以提供修改的服务。因此Redis不满足一致性。
     
     但是Redis保证<mark>最终一致性</mark>。
   
   - 增量同步
     
     Redis主节点会吧对自己状态产生修改性影响的指令记录到本地内存Buffer中，然后异步的将指令buffer同步到从节点。从节点获取指令流执行的同时向主节点反馈偏移量。
     
     Redis中Buffer是一个定长的环形数组，如果buffer写满了就会从头开始覆盖原先的内容。
     
     如果主从网络发生问题，导致从节点长时间没收到buffer的指令流，buffer中的数据随着时间的推移就会被覆盖。
     
     这时我们就需要更加复杂的快照同步。
   
   - 快照同步
     
     主节点将当前内存的数据全部快照到磁盘文件中，然后将快照文件发给从节点，从节点在收到快照后，会执行全量加载，加载之前会将内存数据清空，加载完毕之后从主节点进行增量同步。
     
     但是，如果快照同步时间过长，或者buffer设置太小，都会导致快照同步之后，无法进行增量同步，就会继续发起快照同步。
   
   - 无盘复制
     
     主节点在进行快照同步时，是一件非常耗时的操作，如果发生快照同步，系统正在AOF的fsync时，fsync将会被推迟，会严重影响主节点的服务。
     
     Redis自2.8.18之后支持无盘复制，即主节点将快照内容直接通过套接字发送给从节点，生成快照是个遍历的过程，主节点一边遍历内存，一边将序列化内从发送给从节点。从节点将收到的内容记录在磁盘文件中，最后一次性执行。

2. Sentinel-主从切换
   
   Sentinel负责持续监控主节点的健康。客户端首先会连接Sentinel获取主节点地址，当主节点失效时，客户端会再次向Sentinel查询主节点地址。
   
   消息丢失
   
   Sentinel不能保证数据完全不丢失，但是可以使用两个参数来控制数据主从延迟过大
   
   ```
   min-slaves-to-write 1
   min-slaves-max-lag 10
   ```
   
   第一个表示至少有一个从节点正常复制，否则不提供对外写服务。第二个参数表示从节点10s中没有反馈就表示主从异常复制。

3. Codies 分布式集群
   
   Codies是无状态的，他只是一个转发代理中间件。我们可以启动多个Codies，达到高可用的效果，而且多个Codies还可以提高整体QPS。
   
   **Codies 分片原理**
   
   Codies默认将所有的key 分成1024个槽位，客户端的key到达之后，经过crc32计算hash值，在对1024取余，余数就是key的槽位。Codies中每个槽位都对应了一个Redis实例。
   
   **Codies多实例之间槽位关系的同步**
   
   通过zookeeper将槽位关系存储起来，并提供了一个Codies Dashboard来查看或修改槽位。当槽位关系发生变化时，Codies Proxy会监听变化重新同步槽位关系。
   
   **扩容**
   
   如果有新的实例加入Codies中，则需要对槽位重新分配。意味着原先槽位对应的redis中的key需要转移到新的实例中去。
   
   Codies通过SLOTSSCAN扫描出所有待迁移的key，然后挨个迁移到新的节点。
   
   **代价**
   
   - 不支持事务，key分散在不同的redis实例上
   
   - 不支持rename， 新的key和旧的key 所对应的槽位可能不一样。

4. Cluster Redis官方集群管理
   
   Cluster是去中心化的。他的所有槽位信息都存储在每个Redis实例中。
   
   Cluster中将所有数据划分为16384个槽位，通过crc16计算key的hash,在和16384取余数来定位槽位。
   
   **跳转**
   
   如果客户端向一个错误的节点发送key指令，那个客户端发现该key所在的槽位并不归自己管理，就会返回MOVE指令，携带正确的节点信息给客户端，客户端就会刷新自身的槽位映射。
   
   **迁移**
   
   在迁移过程中，数据访问方式：
   
   客户端会先询问旧节点，如果对应的数据还在旧节点，那么就正常处理，如果不在旧节点，它会向客户端发送一个`ASK targetNodeAddr`的重定向指令。客户端收到指令后先去目标节点执行ASKING指令（<mark>防止重定向循环</mark>），再去执行操作。
   
   重定向循环：
   
   在迁移未完成之前，槽位是不归新节点管理的，他会返回一个MOVE指向旧节点，这样就会导致循环，Asking指令的作用就是强制让新节点处理下一条指令。
   
   **容错**
   
   Cluster允许每个主节点设置若干个从节点，当主节点发生故障时，会将从节点升为主节点
   
   **网络抖动**
   
   网络抖动可能会导致主节点出现不可访问的情况，但是很短的时间又会恢复，为了防止因网络抖动导致频繁的主从切换，Cluster提供了一个选项，cluster-node-time用来表示一个节点失联的最长时间。
   
   **可能下线与确定下线**
   
   Redis采用Gossip协议来**广播自己的状态**及改变对整个集群的认知。
   
   当一个节点发现另一个节点失联时，他会广播这条信息，节点标记为可能下线，如果集群中有一般的节点发现这条消息，那么该节点标记为确定下线。
   
   **集群变更感知**
   
   客户端如何获取节点变更呢？
   
   - 目标节点挂了，客户端会抛出ConnectionError，然后随便挑一个节点发送指令，节点会返回MOVE重定向指令，客户端更新该槽位被更新到新节点的位置。
   
   - 运维手动更改了主从关系。此时客户端指令到旧节点之后，会受到ClusterDown的错误。告知客户端此节点在集群中不可用。此时客户端或清空槽位映射表，带下一条指令来时，重新初始化节点信息。

### 扩展应用

1. Stream
   
   - 结构
     
     Stream极大借鉴了Kafka。它有一个消息链表，将所有加入的消息都串起来，他跟redis一样，有消费组，组内保证唯一消费，组外则是广播。
     
     每个消费组都有一个游标`last_delivered_id`，它表示该消费组的消费位移。消费组需要通过`xgroup create`进行创建，还需要指定初始消费的消费信息的ID。
     
     消费组可有多个消费者，消费者内部有个<mark>PEL</mark>（Pending Entries Lisy），它记录了当前被客户端获取，但是没有ack的消息。
   
   - 消息ID
     
     消息ID由`{timestamp-num}`形式组成，它表示在timestamp时创建的第num条数据。
   
   - 增删改查
     
     > xadd 向Stream追加消息
     > 
     > xdel 从Stream中删除消息，**这里的删除只是设置标记位**。
     > 
     > xrange 获取Stream的消息列表
     > 
     > xlen 获取长度
     > 
     > del 删除Stream中所有消息
     > 
     > xreadgroup 组内消费，需要提供消费组名称，消费者名称和起始ID
     
     ```
     # -表示最小值 +表示最大值 -和+都可以指定具体的ID
     xrange codehole - +
     
     # >代表从group的last_delivered_id开始读取，每读取一条last_delivered_id就+1
     >xreadgroup GROUP cg1 c1 count 1 streams codehole >
     ```
     
     客户端处理完毕之后需要调用xack指令通知服务器。
   
   - 定长Stream
     
     在`xadd`指令中添加定长长度的`maxlen`，可以确保链表不超过有效长度。
     
     ```
     *表示服务器自动生成ID，后面顺序跟着key、value
     xadd codehole maxlen 3 * name xiaorui age 1
     ```
   
   - PEL
     
     Stream中每个消费者都保存了正在处理的消息ID列表PEL，如果消费者没有ack，那么PEL就会不断增长。
     
     PEL中存储了已经发送出去，但是没有收到ack的消息，因此，即使客户端掉线了，也可以重新获取。此时`xreadgroup`起始ID就必须是有效的消息ID，一般为`0-0`，
     
     表示全部PEL消息以及`last_delivered_id`之后的新消息。

2. Info指令
   
   通过Info指令，可以清晰知道Redis内部一系列运行参数。
   
   - Server：服务器运行的环境参数
   
   - Clients：客户端相关信息
   
   - Memory：内存使用情况
   
   - Persistence：持久化
   
   - Stats：通用数据统计
   
   - Replication：主从复制相关
   
   复制积压缓冲区大小：
   
   复制积压缓冲区大小非常重要。当从节点因为网络原因临时断开主节点的复制，在重连之前发生在主节点的修改操作指令都会放在缓存积压区。

3. 集群下的分布式锁
   
   <mark>Redlock算法</mark>
   
   加锁时，它会向过半节点发送setnx指令，当过半节点set成功，就认为加锁成功。释放锁时，也需要向所有节点发送del指令。

4. 过期策略
   
   Redis会将每个设置了过期时间的key放入一个单独的字典中，他会不定时的遍历这个字典来删除过期的key。除了定时遍历，他还会使用惰性策略来删除过期的key。
   
   惰性策略是指在访问这个key的之后，对key的过期时间进行检查，如果过期了就删除。
   
   **定时扫描策略**
   
   Redis默认每秒进行10次过期扫描，过期扫描采用贪心策略
   
   - 从过期词典中选取20个key
   
   - 删除这20个key中过期的部分
   
   - 如果被删除的key比例大于1/4，就重复步骤一。
   
   如果某段时间所有的key都失效了，那么Redis会持续扫描直到key变稀疏，就会导致明显的停顿。导致这种卡顿的现象另一个原因就是数据页频繁被回收。

5. LRU
   
   当Redis内存超过物理内存限制时，内存的数据就会跟磁盘进行交换（swap）。生产环境中为了防止交换，我们需要对Redis内存做限制，当达到最大内存时，就采用如下几种可选策略。
   
   - noeviction：不提供写服务（del可以继续服务），提供读服务
   
   - volatile-lru：尝试淘汰设置了过期时间的key，最少使用的key被优先淘汰。
   
   - volatile-ttl：尝试淘汰设置了过期时间的key，寿命越短的key优先淘汰
   
   - volatile-random：随机淘汰有过期时间的key
   
   - allkeys-lru：针对所有key执行lru算法
   
   - allkeys-random：随机淘汰
   
   如果只是做缓存，使用allkeys-xxx，如果既需要缓存，还需要持久化，那就用volatile-xxx。
   
   **LRU算法**
   
   思想：将最近的访问的对象放到链表的头部，如果超过链表长度，就删除链表尾部的数据。
   
   需要一个词典加上一个链表，对于Redis来说需要花费较大的内存。
   
   Redis中使用的是一种近似的LRU算法。Redis的所有对象头结构中都有一个24bit的字段，他就是用来记录对象的热度。
   
   ```
   typedef struct redisObject{
       unsigned type: 4;    //类型 hash string set zset list
       unsigned encoding:4;  //对象编码 ziplist quicklist,skiplist等
       unsigned lru: 24;  //热度
       int refcount;  //引用计数
       void *ptr;    //数据body
   }
   ```
   
   **Redis中的近似lru**
   
   当内存达到最大内存时，redis会随机抽取5个key，将它们中最旧的key淘汰掉。直到内存小于`maxmemory`为止。

6. 懒惰删除
   
   针对某些比较大的key，譬如存在很多键值对的hash，redis提供了unlink指令，用来将key从引用大树中删除，丢给异步线程池处理。
   
   key被删除之后，会被包装成一个任务交给异步队列，后台线程会从中获取任务执行。由于该队列需要主线程跟后台线程并发处理，因此该队列需要是个线程安全的队列。
   
   ### 

## 内部结构

### SDS（字符串)

Simple Dynamic String。他的结构是一个带信息长度的数组。

```
struct SDS<T> {
    T capacity; //数组容量
    T len; //数组长度
    byte flags; 
    byte[] content;
}
```

capacity表示所分配的数组长度，len表示实际长度，由于字符串支持append操作，因此有预留空间来减少内存的分配。

**embstr vs raw**

字符串在Redis中有两种存储方式，当字符串长度比较小时使用embstr，当字符串长度超过44个字节时，就转换为raw形式存储。

embstr是将Redis对象头和SDS连续存在一起，只需要使用malloc方法一次分配，而raw形式是分开存储的，需要调用两次。

**为什么是44个字节作为分界线呢？**

因为malloc分配内存是以2/4/6/8/16/32/64为单位进行分配的，而Redis头结构占用16个字节，SDS对象头需要占用3个字节，加起来为19个字节，只能以32和64作为分配单位，redis选择64，而且末尾为Null分隔符（方便调用glibc的字符串处理函数），表示字符串结尾，因此64-19-1 = 44.

### 字典dict

除了`hash`整个Redis中所有键值对组成了全局字典。

字典内部有两个`hashtable`，通常情况下只有一个`hashtable`会使用，另一个在扩容或缩容`rehash`时，需要一张新的hashtable，进行渐进式搬迁。

`hashtable`的结构跟java中的`HashMap`很相像，就是一维数据+链表的形式来处理冲突。

**hash攻击**

`hashtable`搜索是需要先定位到一维数组的下标，如果hash函数设计的有偏向性，就会导致所有的key都偏向于某些key，就会导致链表的长度很长。影响整体的搜索效率。

**扩容条件**

当hash表中元素的个数等于一维数组的长度，就会开始扩容，但在bgsave时，不会进行扩容，除非个数到达一维数据的5倍。

### 压缩列表ziplist

当hash和zset中元素较少的时候，就会使用ziplist结构存储。ziplist中元素之间紧挨着存储。

与SDS不同，ziplist不支持扩容，因此当有新的元素增加的时候，就需要重新malloc内存，然后将数据内容一次性拷贝过去。因此其不能存储过多的元素和对象。

压缩列表内存结构

```
struct ziplist<T>{
    int32 zlbytes; //整个压缩列表占用字节数
    int32 zltail_offset; //最后一个元素距离压缩列表起始位置的偏移量，用于快速定位尾部
    int16 zllength; //元素个数
    T[] entries; //元素列表，依次紧凑存储
    int8 zlend;  //压缩标志结束 0xff
}


struct entry{
    int<var> prevlen; //前一个元素entry的长度
    int<var> encoding; //元素编码类型
    optional byte[] content; //内容
}
```

`prevlen`记录了上一个元素的长度，当字符串的长度<254时，使用一个字节表示，当字符串长度大于254时，就使用5个字节表示。

**级联更新**

当一个entry中的内容从253变成了254，那么我们就需要修改后一个entry的prevlen字段。

### 快速列表quicklist（list的存储结构）

<mark>quicklist是ziplist和linkedlist的结合体。</mark>quicklist就是ziplist加上双向指针串起来，形成ziplist作为元素的linkedlist。

quicklist中ziplist的大小默认为8k，超过这个大小就会重新创建。

### 跳表skiptable(zset的存储结构)

**跳表思想**：

跳表是为了在<mark>有序</mark>链表中进行快速查找的一种结构（由于链表无法进行二分查找），链表中每个元素都有50%的概率向上升一层，作为元素索引存在，通过比较索引来快速定位元素所在的区间。（索引不止一层，每层索引最少需要有两个元素）

<mark>zset的内部实现就是一个hash字典加上跳表。</mark>

```
struct zslnode{
    string value;
    double socre;
    zslnode*[] forwards; //多层链接指针
    zslnode* backward;  //回溯指针
}

struct zsl{
    zslnode* header; //跳表头指针
    int maxLevel; //跳表最高层
    map<string, zslnode*> ht; //所有键值对
}
```

**zset怎么获取排名rank的呢**

Redis在skiplist的forward指针上 进行了优化，增加了一个span字段（level0都是1，level1前后两节点中跨过了多少个level0），用来记录从前一个节点沿着当前层的forward指针调到当前节点所经过的节点数。

### LFU vs LRU

LFU更能精准的表达一个key的访问热度，而LRU存在冷数据被偶尔访问就被认为是热数据。

```
typedef struct redisObject{
    unsigned type: 4;    //类型 hash string set zset list
    unsigned encoding:4;  //对象编码 ziplist quicklist,skiplist等
    unsigned lru: 24;  //热度
    int refcount;  //引用计数
    void *ptr;    //数据body
}
```

1. LRU模式
   
   lru模式下，lru字段记录的是Redis的时钟server.lruclock。`lruclock`默认是UNIX时间戳对2^24取模，大概97天清零一次。**当一个key被访问时他的lru就会被更成为server.lruclock。**
   
   **计算一个key的空闲时间**
   
   - 若lru字段的值小于server.lruclock，说明没有发生折返（对2^24取模）。直接用`server.lruclock - obj.lru`就是该key的空闲时间。
   
   - 若lru折返了，则空闲时间为server.lruclock + (LRU_CLOCK_MAX - obj.lru)

2. LFU模式
   
   LFU模式下，**lru字段分为两部分，分别是ldt(last decrement time) 和logc(logistic counter)**
   
   logc是个8bit，用来存储访问频次，这个值存储的是访问频次的对数值，并且这个值会随时间衰减。
   
   ldt是16bit，用来存储上一次logc的时间，也可以看成key的空闲时间，它取得是分钟时间戳对2^16进行取模，大概45天会折返。计算方式跟LRU相同
